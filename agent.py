"""
Asterius Agent - Agente Inteligente com OpenAI
Integra LLM, mem√≥ria e modelo de ML para responder perguntas
"""

import os
import pandas as pd
from typing import Dict, Optional
from openai import OpenAI
from memory import ConversationMemory
from models import SalesPredictor
from utils import IntentDetector, ResponseFormatter, DateFormatter
from schemas import ChatResponse, VisualizationData
"""from database import AsteriusDB"""


class AsteriusAgent:
    """
    Agente inteligente do Asterius.
    Combina OpenAI GPT, mem√≥ria de conversas e modelo de ML.
    """
    
    def __init__(
        self,
        api_key: str,
        model_name: str = "gpt-4",
        temperature: float = 0.7,
        max_tokens: int = 1000,
        memory: Optional[ConversationMemory] = None,
        predictor: Optional[SalesPredictor] = None
    ):
        """
        Inicializa o agente.
        
        Args:
            api_key: Chave da API OpenAI
            model_name: Nome do modelo (gpt-4, gpt-4o, etc.)
            temperature: Criatividade das respostas (0-1)
            max_tokens: M√°ximo de tokens na resposta
            memory: Inst√¢ncia do gerenciador de mem√≥ria
            predictor: Inst√¢ncia do preditor de vendas
        """
        self.client = OpenAI(api_key=api_key)
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # Inicializa componentes
        self.memory = memory or ConversationMemory()
        self.predictor = predictor or SalesPredictor()
    # self.db = AsteriusDB()  # Banco desativado temporariamente
        
        # System prompt do agente
        self.system_prompt = """
Voc√™ √© o Asterius, um assistente inteligente especializado em an√°lise de vendas e previs√µes.

Suas capacidades:
- Analisar dados de vendas e gerar insights
- Fazer previs√µes de vendas futuras
- Responder perguntas sobre o neg√≥cio
- Criar visualiza√ß√µes de dados

Diretrizes:
- Seja direto e objetivo nas respostas
- Use emojis apropriados para deixar a conversa mais amig√°vel
- Quando falar de valores, use o formato brasileiro (R$ 24.500,00)
- Mantenha um tom profissional mas acess√≠vel
- Se n√£o tiver certeza, seja honesto sobre as limita√ß√µes

Quando o usu√°rio pedir previs√µes:
- Gere n√∫meros realistas e bem fundamentados
- Explique brevemente a base da previs√£o
- Destaque pontos importantes (picos, quedas, tend√™ncias)
"""
    
    def respond(self, message: str, session_id: str) -> ChatResponse:
        """
        Processa uma mensagem e retorna resposta.
        
        Args:
            message: Mensagem do usu√°rio
            session_id: ID da sess√£o
            
        Returns:
            ChatResponse com resposta e poss√≠vel visualiza√ß√£o
        """
        try:
            # 1. Detecta a inten√ß√£o
            intent = IntentDetector.detect_intent(message)
            print(f"üéØ Inten√ß√£o detectada: {intent}")
            
            # 2. Recupera contexto da mem√≥ria
            context = self.memory.get_context(session_id)
            
            # 3. Adiciona mensagem do usu√°rio √† mem√≥ria
            self.memory.add_message(session_id, "user", message)
            
            # 4. Se for previs√£o, chama o modelo ML
            if intent == "prediction":
                return self._handle_prediction(message, context)
            
            # 5. Se for consulta de dados, busca no banco
            elif intent == "data_query":
                return self._handle_data_query(message, context, session_id)
            
            # 6. Caso contr√°rio, usa apenas o LLM
            else:
                return self._handle_general_query(message, context, session_id)
        
        except Exception as e:
            print(f"‚ùå Erro no agente: {e}")
            return ChatResponse(
                answer=f"Desculpe, ocorreu um erro ao processar sua mensagem: {str(e)}",
                visualization=None
            )
    
    def _handle_prediction(self, message: str, context: list) -> ChatResponse:
        """
        Trata requisi√ß√µes de previs√£o de vendas com dados meteorol√≥gicos reais.
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto da conversa
            
        Returns:
            ChatResponse com previs√£o e visualiza√ß√£o
        """
        # Extrai n√∫mero de dias da mensagem
        days = IntentDetector.extract_days_from_message(message)
        if days is None:
            days = 7  # Padr√£o: 7 dias
        
        # Extrai loja da mensagem (padr√£o: loja 1)
        loja_id = 1
        if "loja 2" in message.lower() or "segunda loja" in message.lower():
            loja_id = 2
        
        print(f"üìä Gerando previs√£o para {days} dias, loja {loja_id}")
        
        try:
            # Usa o novo modelo XGBoost com dados reais
            from models import XGBoostModel
            model = XGBoostModel()
            
            # Obt√©m predi√ß√µes detalhadas com dados meteorol√≥gicos
            detailed_predictions = model.predict_multiple_days(days, loja_id)
            
            # Extrai valores de predi√ß√£o para compatibilidade
            predictions = [pred['prediction'] for pred in detailed_predictions]
            
            # Extrai dados meteorol√≥gicos reais
            weather_data = []
            for pred in detailed_predictions:
                weather = pred.get('weather_data', {})
                weather_data.append({
                    "date": weather.get('date', ''), 
                    "temperature": weather.get('temp_media', 22.0),
                    "temp_max": weather.get('temp_max', 25.0),
                    "humidity": weather.get('umid_mediana', 65.0),
                    "precipitation": weather.get('precipitacao_total', 0.0),
                    "rain": weather.get('Chuva_aberta', 0.0)
                })
            
            # Formata resposta com visualiza√ß√£o incluindo dados meteorol√≥gicos
            response_data = ResponseFormatter.format_prediction_response(predictions, days)
            
            # Adiciona dados meteorol√≥gicos √† visualiza√ß√£o
            if response_data.get("visualization"):
                response_data["visualization"]["weather_data"] = weather_data
                response_data["visualization"]["charts"]["weather"] = {
                    "temperature": [w["temperature"] for w in weather_data],
                    "precipitation": [w["precipitation"] for w in weather_data],
                    "labels": [w["date"] or f"Dia {i+1}" for i, w in enumerate(weather_data)]
                }
            
            # Enriquece a resposta com o LLM incluindo dados meteorol√≥gicos
            enriched_answer = self._enrich_prediction_with_llm(
                predictions, 
                days, 
                message, 
                context,
                weather_data=weather_data,
                model_status="real" if not model.is_mock else "mock"
            )
            
            # Gera visualiza√ß√£o baseada na pergunta
            visualization = self._generate_chart_for_question(message, detailed_predictions, weather_data)
            
            return ChatResponse(
                answer=enriched_answer,
                visualization=visualization
            )
        
        except Exception as e:
            print(f"‚ùå Erro na previs√£o: {e}")
            return ChatResponse(
                answer=f"Desculpe, n√£o consegui gerar a previs√£o: {str(e)}",
                visualization=None
            )
    
    def _generate_chart_for_question(self, message: str, predictions: list, weather_data: list = None) -> VisualizationData:
        """
        Gera dados de visualiza√ß√£o baseados na pergunta do usu√°rio
        """
        message_lower = message.lower()
        
        # Prepara dados b√°sicos
        dates = [pred.get('date', f"Dia {i+1}") for i, pred in enumerate(predictions)]
        sales_values = [pred.get('prediction', {}).get('vendas_previstas', 0) for pred in predictions]
        
        # Identifica tipo de gr√°fico baseado na pergunta
        if any(word in message_lower for word in ['gr√°fico', 'grafico', 'chart', 'visualiz', 'mostr']):
            
            # Gr√°fico de linha para s√©rie temporal
            if any(word in message_lower for word in ['s√©rie temporal', 'serie temporal', 'linha', 'tend√™ncia', 'tendencia']):
                return VisualizationData(
                    type="line",
                    labels=dates,
                    values=sales_values,
                    extra={
                        "title": "Previs√£o de Vendas - S√©rie Temporal",
                        "colors": ["#3b82f6"]
                    }
                )
            
            # Gr√°fico de barras para compara√ß√£o
            elif any(word in message_lower for word in ['barras', 'bar', 'compar']):
                return VisualizationData(
                    type="bar",
                    labels=dates,
                    values=sales_values,
                    extra={
                        "title": "Previs√£o de Vendas por Dia",
                        "colors": ["#10b981"]
                    }
                )
            
            # Boxplot para distribui√ß√£o
            elif any(word in message_lower for word in ['boxplot', 'distribui√ß√£o', 'distribuicao']):
                return VisualizationData(
                    type="boxplot",
                    labels=["Vendas Previstas"],
                    values=sales_values,
                    extra={
                        "title": "Distribui√ß√£o das Vendas Previstas",
                        "colors": ["#8b5cf6"]
                    }
                )
            
            # Gr√°fico de √°rea
            elif any(word in message_lower for word in ['√°rea', 'area']):
                return VisualizationData(
                    type="area",
                    labels=dates,
                    values=sales_values,
                    extra={
                        "title": "Tend√™ncia de Vendas",
                        "colors": ["#f59e0b"]
                    }
                )
            
            # Scatter plot para correla√ß√£o
            elif any(word in message_lower for word in ['scatter', 'dispers√£o', 'correla√ß√£o']):
                return VisualizationData(
                    type="scatter",
                    labels=dates,
                    values=sales_values,
                    extra={
                        "title": "Vendas vs Fatores Clim√°ticos",
                        "colors": ["#ef4444"]
                    }
                )
            
            # Gr√°fico com dados meteorol√≥gicos
            elif weather_data and any(word in message_lower for word in ['clima', 'tempo', 'meteorol√≥gic', 'chuva', 'temperatura']):
                temp_values = [w.get('temperature', 22) for w in weather_data]
                return VisualizationData(
                    type="line",
                    labels=dates,
                    values=sales_values,
                    extra={
                        "title": "Vendas vs Temperatura",
                        "datasets": [
                            {
                                "label": "Temperatura (¬∞C)",
                                "data": temp_values,
                                "color": "#ef4444"
                            }
                        ]
                    }
                )
            
            # Default: gr√°fico de linha
            else:
                return VisualizationData(
                    type="line",
                    labels=dates,
                    values=sales_values,
                    extra={
                        "title": "Previs√£o de Vendas",
                        "colors": ["#3b82f6"]
                    }
                )
        
        return None
    
    def _enrich_prediction_with_llm(
        self, 
        predictions: list, 
        days: int, 
        message: str,
        context: list,
        weather_data: list = None,
        model_status: str = "mock"
    ) -> str:
        """
        Usa o LLM para gerar uma resposta mais natural sobre a previs√£o incluindo dados meteorol√≥gicos.
        
        Args:
            predictions: Valores previstos
            days: N√∫mero de dias
            message: Mensagem original
            context: Contexto da conversa
            weather_data: Dados meteorol√≥gicos
            model_status: Status do modelo (real/mock)
            
        Returns:
            Resposta enriquecida
        """
        # Calcula estat√≠sticas
        avg = sum(predictions) / len(predictions)
        max_val = max(predictions)
        min_val = min(predictions)
        
        # Prepara informa√ß√µes meteorol√≥gicas
        weather_info = ""
        if weather_data:
            avg_temp = sum(w.get('temperature', 0) for w in weather_data) / len(weather_data)
            total_rain = sum(w.get('precipitation', 0) for w in weather_data)
            weather_info = f"""
Condi√ß√µes meteorol√≥gicas para o per√≠odo:
- Temperatura m√©dia: {avg_temp:.1f}¬∞C
- Precipita√ß√£o total: {total_rain:.1f}mm
- Dados obtidos via NOMADS/GFS
"""
        
        # Monta prompt para o LLM
        prompt = f"""
Com base na previs√£o de vendas e dados meteorol√≥gicos abaixo, gere uma resposta natural e √∫til para o usu√°rio.

Previs√£o para os pr√≥ximos {days} dias:
- Valores: {predictions}
- M√©dia: R$ {avg:,.2f}
- M√°ximo: R$ {max_val:,.2f}
- M√≠nimo: R$ {min_val:,.2f}
- Modelo usado: {"XGBoost Real" if model_status == "real" else "Simulado"}

{weather_info}

Pergunta do usu√°rio: "{message}"

Gere uma resposta que:
1. Apresente os n√∫meros principais
2. Destaque insights importantes (tend√™ncias, picos, correla√ß√£o com clima)
3. Mencione se h√° correla√ß√£o entre clima e vendas
4. Seja concisa (m√°ximo 6 linhas)
5. Use emojis apropriados

Resposta:
"""
        
        # Monta mensagens para a API
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": prompt}
        ]
        
        try:
            # Chama a API OpenAI
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao enriquecer resposta: {e}")
            # Fallback: resposta formatada sem LLM
            return ResponseFormatter.format_prediction_response(predictions, days)["answer"]
    
    def _handle_data_query(self, message: str, context: list, session_id: str) -> ChatResponse:
        """
        Trata consultas de dados hist√≥ricos.
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto da conversa
            session_id: ID da sess√£o
            
        Returns:
            ChatResponse com dados e poss√≠vel visualiza√ß√£o
        """
        try:
            # Detecta tipo de consulta espec√≠fica
            query_info = self._analyze_data_query(message)
            
            # Executa consulta no banco
            data = self._execute_data_query(query_info)
            
            if data is None or data.empty:
                return ChatResponse(
                    answer="Desculpe, n√£o encontrei dados para sua consulta. Tente reformular a pergunta.",
                    visualization=None
                )
            
            # Formata resposta com LLM + visualiza√ß√£o
            return self._format_data_response(data, query_info, message, context, session_id)
            
        except Exception as e:
            print(f"‚ùå Erro na consulta de dados: {e}")
            return ChatResponse(
                answer="Desculpe, houve um erro ao buscar os dados. Tente novamente.",
                visualization=None
            )
    
    def _analyze_data_query(self, message: str) -> Dict:
        """
        Analisa a consulta para determinar tipo e par√¢metros.
        
        Args:
            message: Mensagem do usu√°rio
            
        Returns:
            Dicion√°rio com informa√ß√µes da consulta
        """
        message_lower = message.lower()
        
        query_info = {
            "type": "general",
            "loja_id": None,
            "days": None,
            "limit": 10
        }
        
        # Detecta loja espec√≠fica
        if "loja 1" in message_lower or "primeira loja" in message_lower:
            query_info["loja_id"] = 1
        elif "loja 2" in message_lower or "segunda loja" in message_lower:
            query_info["loja_id"] = 2
        
        # Detecta tipo de consulta
        if any(word in message_lower for word in ["melhores", "maiores", "top", "recordes"]):
            query_info["type"] = "best_days"
        elif any(word in message_lower for word in ["piores", "menores", "baixas"]):
            query_info["type"] = "worst_days"
        elif any(word in message_lower for word in ["clima", "temperatura", "chuva", "correla√ß√£o"]):
            query_info["type"] = "weather"
        elif any(word in message_lower for word in ["√∫ltimos", "recentes", "per√≠odo"]):
            query_info["type"] = "recent"
            # Extrai n√∫mero de dias
            days = IntentDetector.extract_days_from_message(message)
            query_info["days"] = days or 30
        else:
            query_info["type"] = "summary"
        
        return query_info
    
    def _execute_data_query(self, query_info: Dict):
        """
        Executa a consulta no banco de dados.
        
        Args:
            query_info: Informa√ß√µes da consulta
            
        Returns:
            DataFrame com resultados
        """
        query_type = query_info["type"]
        loja_id = query_info["loja_id"]
        
        if query_type == "best_days":
            return self.db.get_best_selling_days(limit=query_info["limit"], loja_id=loja_id)
        elif query_type == "weather":
            return self.db.get_weather_correlation(loja_id=loja_id)
        elif query_type == "recent":
            return self.db.get_sales_by_period(days=query_info["days"], loja_id=loja_id)
        elif query_type == "summary":
            # Retorna resumo das √∫ltimas semanas
            return self.db.get_sales_by_period(days=30, loja_id=loja_id)
        else:
            return self.db.get_sales_by_period(days=30, loja_id=loja_id)
    
    def _format_data_response(self, data, query_info: Dict, message: str, context: list, session_id: str) -> ChatResponse:
        """
        Formata resposta com dados + visualiza√ß√£o usando LLM.
        
        Args:
            data: DataFrame com dados
            query_info: Informa√ß√µes da consulta
            message: Mensagem original
            context: Contexto da conversa
            session_id: ID da sess√£o
            
        Returns:
            ChatResponse formatada
        """
        # Prepara dados para o LLM
        data_summary = self._summarize_data_for_llm(data, query_info)
        
        # Gera resposta enriquecida com LLM
        answer = self._enrich_data_with_llm(data_summary, message, context)
        
        # Cria visualiza√ß√£o se apropriado
        visualization = self._create_data_visualization(data, query_info)
        
        # Salva resposta na mem√≥ria
        self.memory.add_message(session_id, "assistant", answer)
        
        return ChatResponse(
            answer=answer,
            visualization=visualization
        )
    
    def _summarize_data_for_llm(self, data, query_info: Dict) -> str:
        """Cria resumo dos dados para o LLM"""
        if data.empty:
            return "Nenhum dado encontrado."
        
        summary = f"Dados encontrados: {len(data)} registros\n"
        
        if 'valores' in data.columns:
            valores = data['valores'][data['valores'] > 0]
            if not valores.empty:
                summary += f"Vendas - Total: R$ {valores.sum():,.2f}, M√©dia: R$ {valores.mean():,.2f}\n"
                summary += f"Melhor dia: R$ {valores.max():,.2f}, Pior dia: R$ {valores.min():,.2f}\n"
        
        if 'data' in data.columns:
            summary += f"Per√≠odo: {data['data'].min()} a {data['data'].max()}\n"
        
        # Adiciona top 3 resultados para contexto
        if query_info["type"] == "best_days" and len(data) > 0:
            summary += "Top 3 dias:\n"
            for i, row in data.head(3).iterrows():
                summary += f"  {row.get('data', 'N/A')}: R$ {row.get('valores', 0):,.2f}\n"
        
        return summary
    
    def _enrich_data_with_llm(self, data_summary: str, message: str, context: list) -> str:
        """
        Usa LLM para gerar resposta natural sobre os dados.
        
        Args:
            data_summary: Resumo dos dados
            message: Mensagem original
            context: Contexto da conversa
            
        Returns:
            Resposta enriquecida
        """
        prompt = f"""
Com base nos dados abaixo, responda √† pergunta do usu√°rio de forma natural e √∫til.

Dados encontrados:
{data_summary}

Pergunta: "{message}"

Gere uma resposta que:
1. Responda diretamente √† pergunta
2. Destaque os insights mais importantes
3. Use formata√ß√£o brasileira para valores (R$ X.XXX,XX)
4. Seja concisa mas informativa
5. Use emojis apropriados

Resposta:
"""
        
        # Monta mensagens para a API
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": prompt}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao enriquecer resposta de dados: {e}")
            # Fallback: resposta simples
            return f"Encontrei {data_summary.split('registros')[0]}registros nos dados. {data_summary}"
    
    def _create_data_visualization(self, data, query_info: Dict) -> Optional[VisualizationData]:
        """
        Cria visualiza√ß√£o apropriada para os dados.
        
        Args:
            data: DataFrame com dados
            query_info: Informa√ß√µes da consulta
            
        Returns:
            VisualizationData ou None
        """
        if data.empty or len(data) < 2:
            return None
        
        try:
            query_type = query_info["type"]
            
            if query_type == "best_days" and 'valores' in data.columns:
                # Gr√°fico de barras dos melhores dias
                data_viz = data.head(10)
                labels = [str(d)[:10] if pd.notna(d) else f"Dia {i+1}" for i, d in enumerate(data_viz.get('data', range(len(data_viz))))]
                values = data_viz['valores'].fillna(0).tolist()
                
                return VisualizationData(
                    type="bar",
                    labels=labels,
                    values=values,
                    extra={
                        "title": "Melhores Dias de Vendas",
                        "currency": True
                    }
                )
            
            elif query_type == "weather" and 'temperatura' in data.columns:
                # Gr√°fico de dispers√£o temperatura x vendas
                labels = [f"{temp}¬∞C" for temp in data['temperatura']]
                values = data['vendas_media'].fillna(0).tolist()
                
                return VisualizationData(
                    type="line",
                    labels=labels,
                    values=values,
                    extra={
                        "title": "Vendas por Temperatura",
                        "currency": True
                    }
                )
            
            elif query_type in ["recent", "summary"] and 'data' in data.columns:
                # Gr√°fico de linha temporal
                data_sorted = data.sort_values('data').tail(30)  # √öltimos 30 registros
                labels = [str(d)[:10] if pd.notna(d) else f"Dia {i+1}" for i, d in enumerate(data_sorted.get('data', range(len(data_sorted))))]
                values = data_sorted['valores'].fillna(0).tolist()
                
                return VisualizationData(
                    type="line", 
                    labels=labels,
                    values=values,
                    extra={
                        "title": "Vendas no Per√≠odo",
                        "currency": True
                    }
                )
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao criar visualiza√ß√£o: {e}")
        
        return None
    
    def _handle_general_query(self, message: str, context: list, session_id: str) -> ChatResponse:
        """
        Trata perguntas gerais usando apenas o LLM.
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto da conversa
            session_id: ID da sess√£o
            
        Returns:
            ChatResponse com resposta textual
        """
        # Monta mensagens com contexto
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # Adiciona contexto (√∫ltimas 5 mensagens)
        for msg in context[-10:]:  # √öltimas 5 intera√ß√µes (user + assistant)
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # Adiciona mensagem atual
        messages.append({"role": "user", "content": message})
        
        try:
            # Chama a API OpenAI
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            answer = response.choices[0].message.content.strip()
            
            # Salva resposta na mem√≥ria
            self.memory.add_message(session_id, "assistant", answer)
            
            return ChatResponse(
                answer=answer,
                visualization=None
            )
        
        except Exception as e:
            print(f"‚ùå Erro na API OpenAI: {e}")
            return ChatResponse(
                answer="Desculpe, estou com dificuldades para processar sua mensagem no momento. Tente novamente.",
                visualization=None
            )
    
    def get_capabilities(self) -> Dict:
        """Retorna informa√ß√µes sobre as capacidades do agente"""
        return {
            "model": self.model_name,
            "ml_model_loaded": self.predictor.is_loaded,
            "memory_sessions": self.memory.get_session_count(),
            "max_prediction_days": 30
        }
    
    def __repr__(self):
        return f"<AsteriusAgent model={self.model_name} sessions={self.memory.get_session_count()}>"